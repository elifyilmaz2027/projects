{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('test_features.npy')\n",
    "test_labels = np.load('test_labels.npy')\n",
    "train_data = np.load('train_features.npy')\n",
    "train_labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1561, 2)\n",
      "(1561,)\n",
      "(424, 2)\n",
      "(424,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "'''This will be used in prediction part.'''\n",
    "print(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sigmoid function'''\n",
    "def sigmoid(s):\n",
    "    return 1 / (1 + np.exp(-s))\n",
    "\n",
    "\n",
    "'''Here, while computing stochastic gradient descent, \n",
    "we should be careful about using random data points. \n",
    "This part is different from the gradient descent algorithm.\n",
    "Therefore,we can implement logistic regression with stochastic descent.\n",
    "Also, eta refers to learning rate parameter, w0 is bias parameter\n",
    "and w1 and w2 are our weights'''\n",
    "def log_regression_with_sgd(labels, data, eta, epochs):\n",
    "    w0,w1,w2 = 0,0,0\n",
    "    weights = np.array([[w0],[w1],[w2]])\n",
    "    weights_star = []\n",
    "    for epoch in range(epochs):\n",
    "        ein_weights = 0\n",
    "        for j in range(0,len(labels)):\n",
    "            random_index = np.random.randint(0, len(labels))\n",
    "            ein_weights += (labels[random_index]*data[random_index,:])*sigmoid(-labels[random_index]*weights.T @ data[random_index,:]) \n",
    "            stochastic_gradient = -(1/len(labels)*ein_weights)\n",
    "        weights = weights - np.asarray(eta * (stochastic_gradient)).reshape(3,1)   \n",
    "    weights_star.append(weights)\n",
    "    return weights_star\n",
    "\n",
    "def predict_data_sgd(data, weights_star):\n",
    "    return data @ weights_star\n",
    "\n",
    "'''To calculate accuracy, we can use predicted data and our real labels for the test data.'''\n",
    "def accuracy(labels, data, weights_star):\n",
    "    predictions = predict_data_sgd(data, weights_star)\n",
    "    predicted_labels = np.where(predictions > 0 , 1, -1)\n",
    "    correct_labels = np.count_nonzero((np.equal(labels, predicted_labels)))  \n",
    "    return correct_labels / len(labels)\n",
    "\n",
    "\n",
    "\n",
    "def accuracies(train_labels, train_data, test_labels, test_data, eta, epochs):\n",
    "    weights_star = log_regression_with_sgd(train_labels, train_data, eta, epochs)\n",
    "    weights_star = np.array(weights_star).reshape(3,1)\n",
    "    training_accuracy = accuracy(train_labels, train_data, weights_star)\n",
    "    test_accuracy = accuracy(test_labels, test_data, weights_star)\n",
    "    return training_accuracy, test_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here, we should add a column with ones of test and train data for bias\n",
    "because our weights matrix includes bias by first value'''\n",
    "\n",
    "update_train_data = np.append(np.ones((len(train_data),1)),train_data,axis=1)\n",
    "update_test_data = np.append(np.ones((len(test_data),1)),test_data,axis=1)\n",
    "train_labels = train_labels.reshape(1561,1)\n",
    "test_labels = test_labels.reshape(424,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9769378603459321\n",
      "Test accuracy: 0.9528301886792453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''We can choose random values for leaning rate and number of epochs.\n",
    "Here, we selected them as 0.15 and 2000 respectively.'''\n",
    "\n",
    "train_accuracy, test_accuracy = accuracies(train_labels, update_train_data, \n",
    "                                              test_labels, update_test_data, 0.15, 2000)\n",
    "\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
